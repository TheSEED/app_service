#!/bin/sh
#SBATCH --account [% sbatch_account %]
#SBATCH --job-name [% sbatch_job_name %]
#SBATCH --mem [% sbatch_job_mem %]
#SBATCH --nodes 1-1 --ntasks [% n_cpus %]
#SBATCH --export NONE
#SBATCH --comment "[% tasks.0.app.id %]"
[% sbatch_partition %]
[% sbatch_clusters %]

#SBATCH --output [% sbatch_output %]
#SBATCH --err [% sbatch_error %]
#SBATCH --time [% sbatch_time %]
[% IF sbatch_reservation -%]
#SBATCH --reservation [% sbatch_reservation %]
[% END -%]

[% FOR r IN resources -%]
[% r %]
[% END -%]

[%# For a Singularity invocation, we will have variables 
    data_directory (location of data to be bound into /opt/patric-common-data) and
    container_image (location of image to run) 
    defined. Here we will not configure deployment environment details because
    these will be configured internal to the image. 
    We will also bind the job working directory into /tmp in the image, and not
    set any global temp variables. 
-%]

[% IF container_image -%]
[% IF container_repo_url -%]
[% INSERT batch_utils.tt %]
download_compute_image \
	[% container_repo_url %] \
	[% cluster_temp %] \
	[% container_filename %] \
	[% container_cache_dir %]
[% END -%]
[% ELSE -%]
[% configure_deployment -%]
[% END -%]

[% IF p3_allocation -%]
[% p3_allocation %]
[% ELSE -%]
export P3_ALLOCATED_MEMORY="${SLURM_MEM_PER_NODE}M"
export P3_ALLOCATED_CPU=$SLURM_JOB_CPUS_PER_NODE
[% END -%]

[% IF environment_config -%]
[% FOR ent IN environment_config -%]
[% ent %]
[% END -%]
[% END -%]

[% FOR task IN tasks -%]

export P3_AUTH_TOKEN="[% task.token %]"
export KB_AUTH_TOKEN="[% task.token %]"

export WORKDIR=[% cluster_temp %]/task-[% task.id %]-$SLURM_JOB_ID
mkdir $WORKDIR
cd $WORKDIR

cat > app_spec <<'EOSPEC'
[% task.spec %]
EOSPEC

cat > params <<'EOPARAMS'
[% task.params %]
EOPARAMS

export P3_TASK_ID=[% task.id %]

[% IF container_image -%]

if [[ ! -s [% container_image %] ]] ; then
   echo "Container image file [% container_image %] is missing" 1>&2
   exit 1
fi

echo "Running script [% task.script %] in container [% container_image %]"

cd /
export TMPDIR=/tmp
export TEMPDIR=/tmp

singularity run \
	    -H $WORKDIR \
	    -B $WORKDIR:/tmp,[% data_directory %]:/opt/patric-common/data \
	    --pwd /tmp \
	    [% container_image %] \
	    p3x-app-shepherd --app-service [% task.appserv_url %] --task-id [% task.id %] [% task.script %] [% task.monitor_url %] app_spec params &
pid_[% task.id %]=$!
echo "Task [% task.id %] has pid $pid_[% task.id %]"

[% ELSE -%]

export TEMPDIR=[% cluster_temp %]
export TMPDIR=[% cluster_temp %]

echo "Running script [% task.script %]"
p3x-app-shepherd --task-id [% task.id %] [% task.script %] [% task.monitor_url %] app_spec params &
pid_[% task.id %]=$!
echo "Task [% task.id %] has pid $pid_[% task.id %]"

[% END -%]

[% END -%]

[% FOR task IN tasks -%]

pid=$pid_[% task.id %]
echo "Wait for task [% task.id %] $pid"
wait $pid
rc_[% task.id %]=$?
echo "Task [% task.id %] exited with $rc_[% task.id %]"

if [ $rc_[% task.id %] = 0 ] ; then
   rm -rf [% cluster_temp %]/task-[% task.id %]-$SLURM_JOB_ID
fi

[% END -%]

[% IF tasks.size == 1 -%]
exit $rc_[% tasks.0.id %]
[% ELSE -%]
exit 0
[% END -%]

